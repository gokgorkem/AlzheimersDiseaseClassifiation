# -*- coding: utf-8 -*-
"""Biyomedikal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16zTBav7iGluXmsvLLYoWbtGsV4cVHwVC
"""

from google.colab import drive
drive.mount('/content/drive')

!pip3 install tensorflow-addons

import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt

import os
from distutils.dir_util import copy_tree, remove_tree

from PIL import Image
from random import randint

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

from sklearn.metrics import matthews_corrcoef as MCC
from sklearn.metrics import balanced_accuracy_score as BAS
from sklearn.metrics import classification_report, confusion_matrix


import tensorflow_addons as tfa
from keras.utils.vis_utils import plot_model
from tensorflow.keras import Sequential, Input
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.layers import Conv2D, Flatten
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG
from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, MaxPool2D


#Gerekli kütüphanelerin eklenmesi

default_dir = "/content/drive/MyDrive/Alzheimer_sDataset"
root_dir = "/content"
test_dir = default_dir + "/test/"
train_dir = default_dir + "/train/"
work_dir = root_dir + "/dataset/"
#Kaggle çalışma alanında datasetin alınması için yolların belirlenmesi
if os.path.exists(work_dir):
    remove_tree(work_dir)
    

os.mkdir(work_dir)
copy_tree(train_dir, work_dir) #tüm dizinleri tek bir yerde toplama
copy_tree(test_dir, work_dir)

WORK_DIR = '/content/dataset' #çalışma alan tanımı
CLASSES = [ 'NonDemented',
            'VeryMildDemented',
            'MildDemented',
            'ModerateDemented'] #liste şeklinde sınıfların tanınlanması

IMG_SIZE = 176   #imagelerin tek bir boyutta oluşturulması
IMAGE_SIZE = [176, 176]
DIM = (IMG_SIZE, IMG_SIZE)

ZOOM = [.99, 1.01]  #image oranının korunması
BRIGHT_RANGE = [0.8, 1.2]   #parlaklık oranının arttırılması
HORZ_FLIP = True
FILL_MODE = "constant"
DATA_FORMAT = "channels_last" #image data generator için gerekli tanımlamaların yapılması

work_dr = IDG(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM, data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)

train_data_gen = work_dr.flow_from_directory(directory=WORK_DIR, target_size=DIM, batch_size=6400, shuffle=False)

def show_images(generator,y_pred=None, nn=6400):

    """
    Input: bir resim oluşturucu, tahmin edilen etiketler
    Output: ızgara şeklinde 9 etiketli çıktıyı gösterir
    """
    
    # görüntü etiketleri alma
    labels =dict(zip([0,1,2,3], CLASSES))
    
    #toplu resim alma
    x,y = generator.next()
    
    # 9 resimlik bir ızgara göster
    plt.figure(figsize=(10, 10))
    if y_pred is None:
        for i in range(9):
            ax = plt.subplot(3, 3, i + 1)
            idx = randint(0, nn)
            plt.imshow(x[idx])
            plt.axis("off")   
            plt.title("Class:{}".format(labels[np.argmax(y[idx])]))
                                                     
    else:
        for i in range(9):
            ax = plt.subplot(3, 3, i + 1)
            plt.imshow(x[i])
            plt.axis("off")
            plt.title("Actual:{} \nPredicted:{}".format(labels[np.argmax(y[i])],labels[y_pred[i]]))
    
# Train Görüntülerini Görüntüle
show_images(train_data_gen,nn=6400)

train_data, train_labels = train_data_gen.next()   #train datalarının oluşturulması

train_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)
train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)

#eğitim ve test dataları ayrılarak %20'lik dilimde test verileri oluşturulmaktadır.

#train data
sm = SMOTE(random_state=42)  #tüm sınıflardaki imagelerin aynı sayıda olmasını sağlar.

train_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)  
#tüm sınıflardaki imageler aynı sayıya eşitlenir.

train_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)  #train data tekrar düzenlenir

print(train_data.shape, train_labels.shape)

# OVER SAMPLING
# - validation data
val_data, val_labels = sm.fit_resample(val_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), val_labels)

val_data = val_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)

print(val_data.shape, val_labels.shape)

# OVER SAMPLING
# - test data
test_data, test_labels = sm.fit_resample(test_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), test_labels)

test_data = test_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)

print(test_data.shape, test_labels.shape)

#Evrişimli Sinir Ağı Mimarisi Oluşturma^
#sıralı cnnn modeli için konvisyonel yapay sinir blogu tanımlanması

def conv_block(filters, act='relu'):
    """Sıralı CNN modeli için Evrişimsel NN bloğu tanımlama. """
    
    block = Sequential()
    block.add(Conv2D(filters, 3, activation=act, padding='same'))
    block.add(Conv2D(filters, 3, activation=act, padding='same'))
    block.add(BatchNormalization())
    block.add(MaxPool2D())
    
    return block

#sıralı cnnn modeli için yoğun yapay sinir blogu tanımlanması

def dense_block(units, dropout_rate, act='relu'):
    """Defining a Dense NN block for a Sequential CNN model. """
    
    block = Sequential()
    block.add(Dense(units, activation=act))
    block.add(BatchNormalization())
    block.add(Dropout(dropout_rate))
    
    return block

#Sınıflandırma görevini gerçekleştirmek için Sıralı CNN mimarisi oluşturma
def construct_model(act='relu'):
    """Constructing a Sequential CNN architecture for performing the classification task. """
    
    model = Sequential([
        Input(shape=(*IMAGE_SIZE, 3)),
        Conv2D(16, 3, activation=act, padding='same'),
        Conv2D(16, 3, activation=act, padding='same'),
        MaxPool2D(),
        conv_block(32),
        conv_block(64),
        conv_block(128),
        Dropout(0.2),
        conv_block(256),
        Dropout(0.2),
        Flatten(),
        dense_block(512, 0.7),
        dense_block(128, 0.5),
        dense_block(64, 0.3),
        Dense(4, activation='softmax')        
    ], name = "cnn_model")

    return model

#Doğruluk %99'un üzerine çıktığında modelimizi eğitmeyi durdurmak için özel bir geri arama işlevi tanımlama

class MyCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if logs.get('val_acc') > 0.99:
            print("\nReached accuracy threshold! Terminating training.")
            self.model.stop_training = True
            
my_callback = MyCallback()

#Modelin her zaman öğrendiğinden emin olmak için #EarlyStopping geri arama
early_stopping = EarlyStopping(monitor='val_loss', patience=2)

#CNN modelimiz için diğer parametreleri tanımlama
model = construct_model()

METRICS = [tf.keras.metrics.CategoricalAccuracy(name='acc'),
           tf.keras.metrics.AUC(name='auc'), 
           tfa.metrics.F1Score(num_classes=4)]

CALLBACKS = [my_callback]


model.compile(optimizer='adam',
              loss=tf.losses.CategoricalCrossentropy(),
              metrics=METRICS)

model.summary()

#Eğitim verilerini modele sığdırma ve doğrulama verilerini kullanarak doğrulama
#Modeli Eğitim ve Test Etme
EPOCHS = 60

history = model.fit(train_data, train_labels, validation_data=(val_data, val_labels), callbacks=CALLBACKS, batch_size=16,epochs=EPOCHS)

!mkdir -p saved_model
model.save('saved_model/my_model')



#Eğitim sırasında metricleri grafik olarak çizme
fig, ax = plt.subplots(1, 3, figsize = (30, 5))
ax = ax.ravel()

for i, metric in enumerate(["acc", "auc", "loss"]):
    ax[i].plot(history.history[metric])
    ax[i].plot(history.history["val_" + metric])
    ax[i].set_title("Model {}".format(metric))
    ax[i].set_xlabel("Epochs")
    ax[i].set_ylabel(metric)
    ax[i].legend(["train", "val"])

#Veriler üzerinde modelin değerlendirilmesi
#train_scores = model.evaluate(train_data, train_labels)
#val_scores = model.evaluate(val_data, val_labels)
test_scores = model.evaluate(test_data, test_labels)

#print("Training Accuracy: %.2f%%"%(train_scores[1] * 100))
#print("Validation Accuracy: %.2f%%"%(val_scores[1] * 100))
print("Testing Accuracy: %.2f%%"%(test_scores[1] * 100))